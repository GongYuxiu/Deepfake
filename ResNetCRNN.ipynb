{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # 按照PCI_BUS_ID顺序从0开始排列GPU设备 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #设置当前使用的GPU设备仅为0号设备  设备名称为'/gpu:0'import sys\n",
    "# set path\n",
    "temp = [0,1]\n",
    "with open('filename.pkl','wb') as f:\n",
    "    pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "data_path = \"/home/jovyan/work/data/gyx/competition_face/train_face_img/\"    # define RGB data path\n",
    "action_name_path = './filename.pkl'\n",
    "save_model_path = \"./ResNetCRNN_ckpt/\"\n",
    "\n",
    "# EncoderCNN architecture\n",
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 768\n",
    "CNN_embed_dim = 512   # latent dim extracted by 2D CNN\n",
    "res_size = 224        # ResNet image size\n",
    "dropout_p = 0.0       # dropout probability\n",
    "\n",
    "# DecoderRNN architecture\n",
    "RNN_hidden_layers = 3\n",
    "RNN_hidden_nodes = 512\n",
    "RNN_FC_dim = 256\n",
    "\n",
    "# training parameters\n",
    "k = 2          # number of target category\n",
    "epochs = 120        # training epochs\n",
    "batch_size = 40  \n",
    "learning_rate = 1e-3\n",
    "log_interval = 10   # interval for displaying training info\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 11, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    cnn_encoder, rnn_decoder = model\n",
    "    cnn_encoder.train()\n",
    "    rnn_decoder.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn_decoder(cnn_encoder(X))   # output has dim = (batch, number of classes)\n",
    "\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 1)[1]  # y_pred != output\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    cnn_encoder, rnn_decoder = model\n",
    "    cnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device).view(-1, )\n",
    "\n",
    "            output = rnn_decoder(cnn_encoder(X))\n",
    "\n",
    "            loss = F.cross_entropy(output, y, reduction='sum')\n",
    "            test_loss += loss.item()                 # sum up batch loss\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "\n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # compute accuracy\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "# load UCF101 actions names\n",
    "with open(action_name_path, 'rb') as f:\n",
    "    action_names = pickle.load(f)\n",
    "\n",
    "# convert labels -> category\n",
    "le = LabelEncoder()\n",
    "le.fit(action_names)\n",
    "\n",
    "# show how many classes there are\n",
    "list(le.classes_)\n",
    "\n",
    "# convert category -> 1-hot\n",
    "action_category = le.transform(action_names).reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(action_category)\n",
    "\n",
    "# # example\n",
    "# y = ['HorseRace', 'YoYo', 'WalkingWithDog']\n",
    "# y_onehot = labels2onehot(enc, le, y)\n",
    "# y2 = onehot2labels(le, y_onehot)\n",
    "\n",
    "actions = []\n",
    "fnames = os.listdir(data_path)\n",
    "# print('fnames',fnames[0]) #'adylbeequz_10_FAKE.jpg'\n",
    "all_names = []\n",
    "all_labels = []\n",
    "for f in fnames:\n",
    "    name=f\n",
    "    label=f.split('.jpg')[0].split('_')[2]   \n",
    "    all_names.append(name)\n",
    "    if label=='FAKE':\n",
    "        label_NUM=0\n",
    "    else:\n",
    "        label_NUM=1\n",
    "    all_labels.append(label_NUM)\n",
    "    \n",
    "\n",
    "# list all data files\n",
    "all_X_list = all_names                  # all video file names\n",
    "all_y_list = all_labels    # all video labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "train_list, test_list, train_label, test_label = train_test_split(all_X_list, all_y_list, test_size=0.25, random_state=42)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([res_size, res_size]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
    "print(selected_frames)\n",
    "train_set, valid_set = Dataset_CRNN(data_path, train_list, train_label, selected_frames, transform=transform), \\\n",
    "                       Dataset_CRNN(data_path, test_list, test_label, selected_frames, transform=transform)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, **params)\n",
    "valid_loader = data.DataLoader(valid_set, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "cnn_encoder = ResCNNEncoder(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
    "rnn_decoder = DecoderRNN(CNN_embed_dim=CNN_embed_dim, h_RNN_layers=RNN_hidden_layers, h_RNN=RNN_hidden_nodes, \n",
    "                         h_FC_dim=RNN_FC_dim, drop_p=dropout_p, num_classes=k).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize model to multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    cnn_encoder = nn.DataParallel(cnn_encoder)\n",
    "    rnn_decoder = nn.DataParallel(rnn_decoder)\n",
    "\n",
    "    # Combine all EncoderCNN + DecoderRNN parameters\n",
    "    crnn_params = list(cnn_encoder.module.fc1.parameters()) + list(cnn_encoder.module.bn1.parameters()) + \\\n",
    "                  list(cnn_encoder.module.fc2.parameters()) + list(cnn_encoder.module.bn2.parameters()) + \\\n",
    "                  list(cnn_encoder.module.fc3.parameters()) + list(rnn_decoder.parameters())\n",
    "\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
    "    # Combine all EncoderCNN + DecoderRNN parameters\n",
    "    crnn_params = list(cnn_encoder.fc1.parameters()) + list(cnn_encoder.bn1.parameters()) + \\\n",
    "                  list(cnn_encoder.fc2.parameters()) + list(cnn_encoder.bn2.parameters()) + \\\n",
    "                  list(cnn_encoder.fc3.parameters()) + list(rnn_decoder.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(crnn_params, lr=learning_rate)\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_train_scores = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_scores = []\n",
    "\n",
    "# start training\n",
    "test_score=0\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    train_losses, train_scores = train(log_interval, [cnn_encoder, rnn_decoder], device, train_loader, optimizer, epoch)\n",
    "    epoch_test_loss, epoch_test_score = validation([cnn_encoder, rnn_decoder], device, optimizer, valid_loader)\n",
    "    \n",
    "    # save Pytorch models of best record\n",
    "    if  not os.path.exists(save_model_path):#如果路径不存在\n",
    "        os.makedirs(save_model_path)\n",
    "    if  epoch_test_score > test_score:\n",
    "        test_score=epoch_test_score\n",
    "        torch.save(cnn_encoder.state_dict(), os.path.join(save_model_path, 'cnn_encoder_epoch{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "        torch.save(rnn_decoder.state_dict(), os.path.join(save_model_path, 'rnn_decoder_epoch{}.pth'.format(epoch + 1)))  # save motion_encoder\n",
    "        torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "        print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    # save results\n",
    "    epoch_train_losses.append(train_losses)\n",
    "    epoch_train_scores.append(train_scores)\n",
    "    epoch_test_losses.append(epoch_test_loss)\n",
    "    epoch_test_scores.append(epoch_test_score)\n",
    "\n",
    "    # save all train test results\n",
    "    A = np.array(epoch_train_losses)\n",
    "    B = np.array(epoch_train_scores)\n",
    "    C = np.array(epoch_test_losses)\n",
    "    D = np.array(epoch_test_scores)\n",
    "    np.save('./CRNN_epoch_training_losses.npy', A)\n",
    "    np.save('./CRNN_epoch_training_scores.npy', B)\n",
    "    np.save('./CRNN_epoch_test_loss.npy', C)\n",
    "    np.save('./CRNN_epoch_test_score.npy', D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "epochs=32\n",
    "plt.plot(np.arange(1, epochs + 1), A[:, -1])  # train loss (on epoch end)\n",
    "plt.plot(np.arange(1, epochs + 1), C)         #  test loss (on epoch end)\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "# 2nd figure\n",
    "plt.subplot(122)\n",
    "plt.plot(np.arange(1, epochs + 1), B[:, -1])  # train accuracy (on epoch end)\n",
    "plt.plot(np.arange(1, epochs + 1), D)         #  test accuracy (on epoch end)\n",
    "plt.title(\"training scores\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "title = \"./fig_UCF101_ResNetCRNN.png\"\n",
    "plt.savefig(title, dpi=600)\n",
    "# plt.close(fig)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import pickle\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # 按照PCI_BUS_ID顺序从0开始排列GPU设备 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #设置当前使用的GPU设备仅为0号设备  设备名称为'/gpu:0'import sys\n",
    "# set path\n",
    "data_path = \"/home/jovyan/work/data/gyx/competition_face/test_face_img/\"                # define UCF-101 RGB data path\n",
    "action_name_path = \"./filename.pkl\"\n",
    "save_model_path = \"./ResNetCRNN_ckpt/\"\n",
    "\n",
    "# use same encoder CNN saved!\n",
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 768\n",
    "CNN_embed_dim = 512   # latent dim extracted by 2D CNN\n",
    "res_size = 224        # ResNet image size\n",
    "dropout_p = 0.0       # dropout probability\n",
    "\n",
    "# use same decoder RNN saved!\n",
    "RNN_hidden_layers = 3\n",
    "RNN_hidden_nodes = 512\n",
    "RNN_FC_dim = 256\n",
    "\n",
    "# training parameters\n",
    "k = 2             # number of target category\n",
    "batch_size = 40\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 11, 1\n",
    "\n",
    "\n",
    "with open(action_name_path, 'rb') as f:\n",
    "    action_names = pickle.load(f)   # load UCF101 actions names\n",
    "\n",
    "# convert labels -> category\n",
    "le = LabelEncoder()\n",
    "le.fit(action_names)\n",
    "\n",
    "# show how many classes there are\n",
    "list(le.classes_)\n",
    "\n",
    "# convert category -> 1-hot\n",
    "action_category = le.transform(action_names).reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(action_category)\n",
    "\n",
    "# # example\n",
    "# y = ['HorseRace', 'YoYo', 'WalkingWithDog']\n",
    "# y_onehot = labels2onehot(enc, le, y)\n",
    "# y2 = onehot2labels(le, y_onehot)\n",
    "\n",
    "actions = []\n",
    "fnames = os.listdir(data_path)\n",
    "# print('fnames',fnames[0]) #'adylbeequz_10_FAKE.jpg'\n",
    "all_names = []\n",
    "all_labels = []\n",
    "for f in fnames:\n",
    "    all_names.append(f)   \n",
    "    \n",
    "\n",
    "# list all data files\n",
    "all_X_list = all_names                  # all video file names\n",
    "\n",
    "\n",
    "# data loading parameters\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([res_size, res_size]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_CRNN_test(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, folders, frames, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.data_path = data_path\n",
    "        self.folders = folders\n",
    "        self.transform = transform\n",
    "        self.frames = frames\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(self.folders)\n",
    "\n",
    "    def read_images(self, path, selected_folder, use_transform):\n",
    "        X = []\n",
    "        for i in self.frames:\n",
    "            image = Image.open(os.path.join(path, selected_folder))\n",
    "#             image = Image.open(os.path.join(path, selected_folder, 'frame{:06d}.jpg'.format(i)))\n",
    "\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        # Select sample\n",
    "        folder = self.folders[index]\n",
    "\n",
    "        # Load data\n",
    "        X = self.read_images(self.data_path, folder, self.transform)     # (input) spatial images\n",
    "        \n",
    "        # print(X.shape)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN model reloaded!\n"
     ]
    }
   ],
   "source": [
    "# reset data loader\n",
    "all_data_params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "all_data_loader = data.DataLoader(Dataset_CRNN_test(data_path, all_X_list, selected_frames, transform=transform), **all_data_params)\n",
    "\n",
    "\n",
    "# reload CRNN model\n",
    "cnn_encoder = ResCNNEncoder(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
    "rnn_decoder = DecoderRNN(CNN_embed_dim=CNN_embed_dim, h_RNN_layers=RNN_hidden_layers, h_RNN=RNN_hidden_nodes, \n",
    "                         h_FC_dim=RNN_FC_dim, drop_p=dropout_p, num_classes=k).to(device)\n",
    "\n",
    "cnn_encoder.load_state_dict(torch.load(os.path.join(save_model_path, 'cnn_encoder_epoch14.pth')))\n",
    "rnn_decoder.load_state_dict(torch.load(os.path.join(save_model_path, 'rnn_decoder_epoch14.pth')))\n",
    "print('CRNN model reloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting all 400.0 videos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:54<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# make all video predictions by reloaded model\n",
    "print('Predicting all {} videos:'.format(len(all_data_loader.dataset)/10))\n",
    "all_y_pred = CRNN_final_prediction([cnn_encoder, rnn_decoder], device, all_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video prediction finished!\n"
     ]
    }
   ],
   "source": [
    "# write in pandas dataframe\n",
    "df = pd.DataFrame(data={'filename': fnames, 'y_pred': cat2labels(le, all_y_pred)})\n",
    "df.to_pickle(\"./face_videos_prediction_new.pkl\")  # save pandas dataframe\n",
    "# pd.read_pickle(\"./all_videos_prediction.pkl\")\n",
    "print('video prediction finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./face_videos_prediction.pkl')\n",
    "df_new = pd.read_pickle('./face_videos_prediction_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_new_1=df_new\n",
    "for i in range(len(df_new_1['filename'])):\n",
    "    df_new_1['filename'][i]=df_new_1['filename'][i].split('.jpg')[0].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2=df_new_1.groupby('filename').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_new_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
